import os
import sys
import PyPDF2
import openai
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import TextLoader, PyPDFLoader
from langchain.embeddings import OpenAIEmbeddings
from langchain.indexes import VectorstoreIndexCreator
from langchain.vectorstores import Chroma

import constants

os.environ["OPENAI_API_KEY"] = constants.APIKEY

query = None
if len(sys.argv) > 1:
    query = sys.argv[1]

loader = TextLoader("C:/Users/Ankur Sharma/Desktop/Chatbot/chatgpt-retrieval-main/chatgpt-retrieval-main/data/data.txt")

# Add PyPDFLoader to the list of loaders
loaders = [loader]

# Provide the 'file_path' argument when creating the PyPDFLoader instance
pdf_loader = PyPDFLoader(file_path="C:/Users/Ankur Sharma/Desktop/Chatbot/chatgpt-retrieval-main/chatgpt-retrieval-main/data/Mountain Training Plan - Module 1.pdf")
loaders.append(pdf_loader)

# Extract text from the PDF document using PyPDF2
with open("C:/Users/Ankur Sharma/Desktop/Chatbot/chatgpt-retrieval-main/chatgpt-retrieval-main/data/Mountain Training Plan - Module 1.pdf", "rb") as file:
    pdf_reader = PyPDF2.PdfFileReader(file)
    pdf_text = ""
    for page_num in range(pdf_reader.numPages):
        page = pdf_reader.getPage(page_num)
        pdf_text += page.extractText()

index = VectorstoreIndexCreator().from_loaders(loaders)

chain = ConversationalRetrievalChain.from_llm(
    llm=ChatOpenAI(model="gpt-3.5-turbo"),
    retriever=index.vectorstore.as_retriever(search_kwargs={"k": 1}),
)

chat_history = []
while True:
    if not query:
        query = input("Prompt: ")
    if query in ['quit', 'q', 'exit']:
        sys.exit()

    try:
        result = chain({"question": query, "chat_history": chat_history})
        print(result['answer'])
    except IndexError as e:
        print(f"An error occurred: {e}")

    chat_history.append((query, result['answer']))
    query = None
